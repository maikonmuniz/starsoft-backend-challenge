version: '3.8'

services:
  api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: app
    ports:
      - '5050:5050'
    volumes:
      - .:/app
      - /app/node_modules
    command: yarn start:dev
    depends_on:
      - db
      - kafka
      - elasticsearch
      - logstash
    environment:
      DATABASE_HOST: db
      DATABASE_PORT: 5432
      DATABASE_USER: ${DATABASE_USER}
      DATABASE_PASSWORD: ${DATABASE_PASSWORD}
      DATABASE_NAME: ${DATABASE_NAME}
      KAFKA_BROKER: kafka:29092
    networks:
      - app-net
      - rede-elastic-kibana

  db:
    image: postgres:15
    container_name: postgres-container-app
    restart: always
    environment:
      POSTGRES_USER: ${DATABASE_USER}
      POSTGRES_PASSWORD: ${DATABASE_PASSWORD}
      POSTGRES_DB: ${DATABASE_NAME}
    ports:
      - '5432:5432'
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - app-net

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
    ports:
      - "3000:3000"
    volumes:
      - grafana-storage:/var/lib/grafana
    restart: unless-stopped

  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.2
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - "2183:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - app-net

  kafka:
    image: confluentinc/cp-server:7.5.2
    command: bash -c "sleep 30 && /etc/confluent/docker/run"
    init: true
    hostname: kafka
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "9101:9101"
      - "9094:9094"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092,OUTSIDE://host.docker.internal:9094
      KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
      KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: kafka:29092
      CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1
      CONFLUENT_METRICS_ENABLE: "true"
      CONFLUENT_SUPPORT_CUSTOMER_ID: "anonymous"
    healthcheck:
      test: kafka-topics --bootstrap-server kafka:9092 --list
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - app-net

  schema-registry:
    image: confluentinc/cp-schema-registry:7.5.2
    hostname: schema-registry
    container_name: schema-registry
    depends_on:
      kafka:
        condition: service_healthy
    ports:
      - "8081:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: "kafka:29092"
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
    networks:
      - app-net

  ksqldb-server:
    image: confluentinc/ksqldb-server:0.29.0
    hostname: ksqldb-server
    container_name: ksqldb-server
    depends_on:
      - kafka
      - schema-registry
    ports:
      - "8088:8088"
    environment:
      KSQL_LISTENERS: "http://0.0.0.0:8088"
      KSQL_BOOTSTRAP_SERVERS: "kafka:29092"
      KSQL_KSQL_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
      KSQL_LOG4J_ROOT_LOGLEVEL: "ERROR"
      KSQL_LOG4J_LOGGERS: "org.apache.kafka.connect.runtime.rest=WARN,org.reflections=ERROR"
      KSQL_LOG4J_PROCESSING_LOG_BROKERLIST: kafka:29092
      KSQL_LOG4J_PROCESSING_LOG_TOPIC: ksql-processing-log-topic-name
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_NAME: ksql-processing-log-topic-name
      KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: "true"
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: "true"
    networks:
      - app-net

  ksqldb-cli:
    image: confluentinc/ksqldb-cli:0.29.0
    container_name: ksqldb-cli
    depends_on:
      - kafka
      - ksqldb-server
    entrypoint: /bin/sh
    tty: true
    networks:
      - app-net

  redpandadata:
    image: docker.redpanda.com/redpandadata/console:v2.4.3
    container_name: redpandadata
    entrypoint: /bin/sh
    command: -c "echo \"$$CONSOLE_CONFIG_FILE\" > /tmp/config.yml; /app/console"
    environment:
      CONFIG_FILEPATH: /tmp/config.yml
      CONSOLE_CONFIG_FILE: |
        kafka:
          brokers: ["kafka:29092"]
    ports:
      - "8080:8080"
    depends_on:
      kafka:
        condition: service_healthy
    networks:
      - app-net

  elasticsearch:
    image: elasticsearch:7.17.23
    container_name: elasticsearch
    hostname: elasticsearch
    deploy:
      resources:
        limits:
          cpus: "0.95"
          memory: 4G
    restart: always
    environment:
      - node.name=elasticsearch
      - discovery.type=single-node
      - xpack.security.enabled=true 
      - cluster.name=docker-cluster
      - ELASTIC_PASSWORD=${ELASTIC_PASS}
      - TZ=America/Sao_Paulo
    healthcheck:
      test: curl -u elastic:${ELASTIC_PASS} -f http://elasticsearch:9200/_cluster/health || exit 1
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    volumes:
      - elastic_data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
    networks:
      - rede-elastic-kibana

  kibana:
    depends_on:
       - elasticsearch
    image: kibana:7.17.23
    container_name: kibana
    hostname: kibana
    deploy:
      resources:
        limits:
          cpus: "0.95"
          memory: 2G
    restart: always
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      - ELASTICSEARCH_USERNAME=elastic
      - ELASTICSEARCH_PASSWORD=${ELASTIC_PASS}
      - TZ=America/Sao_Paulo
    healthcheck:
      test: curl -f http://kibana:5601/ || exit 1
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 15s
    ports:
      - "5601:5601"
    networks:
      - rede-elastic-kibana

  logstash:
    image: docker.elastic.co/logstash/logstash:7.17.23
    container_name: logstash
    depends_on:
      - kafka
      - elasticsearch
    ports:
      - "5044:5044"
      - "9600:9600"
    volumes:
      - ./logstash/pipeline:/usr/share/logstash/pipeline:ro
    environment:
      - LS_JAVA_OPTS=-Xms512m -Xmx512m
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    networks:
      - app-net
      - rede-elastic-kibana

volumes:
  postgres_data:
  grafana-storage:
  elastic_data:

networks:
  app-net:
    driver: bridge
  rede-elastic-kibana:
    driver: bridge
